{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f37f9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from src.utility.logger import append_log\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7bdd9b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact duplicates found: 0\n",
      "Total rows involved in duplication: 0\n",
      "Duplicates based on time: 0\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('data/raw/combined_iasi_no2_meteo_2020_2025_local.csv')\n",
    "\n",
    "# Check for exact duplicates across all columns\n",
    "exact_duplicates = df.duplicated().sum()\n",
    "print(f\"Exact duplicates found: {exact_duplicates}\")\n",
    "\n",
    "# View duplicate rows\n",
    "duplicate_rows = df[df.duplicated(keep=False)]\n",
    "print(f\"Total rows involved in duplication: {len(duplicate_rows)}\")\n",
    "\n",
    "# Check duplicates on specific key columns\n",
    "key_duplicates = df.duplicated(subset=['datetime']).sum()\n",
    "print(f\"Duplicates based on time: {key_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91b1a373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate key patterns:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Remove exact duplicates (keep first occurrence)\n",
    "df_cleaned = df.drop_duplicates(keep='first')\n",
    "\n",
    "# For key-based duplicates, investigate first\n",
    "duplicate_keys = df[df.duplicated(subset=['datetime'], keep=False)]\n",
    "print(\"Duplicate key patterns:\")\n",
    "print(duplicate_keys.groupby(['datetime']).size().sort_values(ascending=False))\n",
    "\n",
    "# Remove duplicates based on key columns after investigation\n",
    "df_cleaned = df.drop_duplicates(subset=['datetime'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "793f43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_log(\n",
    "    \"outputs/logs/data_cleaning_log.txt\",\n",
    "    [\n",
    "        f\"Original dataset: {len(df)} rows\",\n",
    "        f\"Exact duplicates removed: {exact_duplicates}\",\n",
    "        f\"Key-based duplicates removed: {key_duplicates}\",\n",
    "        f\"Final dataset: {len(df_cleaned)} rows\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "17c85560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>sensors_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>value</th>\n",
       "      <th>temp_C</th>\n",
       "      <th>dewpoint_C</th>\n",
       "      <th>slp_hPa</th>\n",
       "      <th>wind_dir_deg</th>\n",
       "      <th>wind_speed_ms</th>\n",
       "      <th>precip_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22081.0</td>\n",
       "      <td>22081.0</td>\n",
       "      <td>22081.000000</td>\n",
       "      <td>22081.000000</td>\n",
       "      <td>22081.000000</td>\n",
       "      <td>48674.000000</td>\n",
       "      <td>48674.000000</td>\n",
       "      <td>48674.000000</td>\n",
       "      <td>48253.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48674.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9369.0</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>47.156800</td>\n",
       "      <td>27.574886</td>\n",
       "      <td>31.661637</td>\n",
       "      <td>119.342400</td>\n",
       "      <td>58.548198</td>\n",
       "      <td>10085.463286</td>\n",
       "      <td>31.269538</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>165.729178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>30.498318</td>\n",
       "      <td>97.136655</td>\n",
       "      <td>100.504995</td>\n",
       "      <td>1349.646573</td>\n",
       "      <td>101.462163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>364.906361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9369.0</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>47.156766</td>\n",
       "      <td>27.574866</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-168.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9369.0</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>47.156766</td>\n",
       "      <td>27.574866</td>\n",
       "      <td>15.896116</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10122.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9369.0</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>47.156766</td>\n",
       "      <td>27.574866</td>\n",
       "      <td>29.376155</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>10169.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9369.0</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>47.156836</td>\n",
       "      <td>27.574908</td>\n",
       "      <td>43.917378</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>10226.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9369.0</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>47.156836</td>\n",
       "      <td>27.574908</td>\n",
       "      <td>2217.676463</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>10474.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       location_id  sensors_id           lat           lon         value  \\\n",
       "count      22081.0     22081.0  22081.000000  22081.000000  22081.000000   \n",
       "mean        9369.0     28602.0     47.156800     27.574886     31.661637   \n",
       "std            0.0         0.0      0.000035      0.000021     30.498318   \n",
       "min         9369.0     28602.0     47.156766     27.574866     -1.000000   \n",
       "25%         9369.0     28602.0     47.156766     27.574866     15.896116   \n",
       "50%         9369.0     28602.0     47.156766     27.574866     29.376155   \n",
       "75%         9369.0     28602.0     47.156836     27.574908     43.917378   \n",
       "max         9369.0     28602.0     47.156836     27.574908   2217.676463   \n",
       "\n",
       "             temp_C    dewpoint_C       slp_hPa  wind_dir_deg  wind_speed_ms  \\\n",
       "count  48674.000000  48674.000000  48674.000000  48253.000000            6.0   \n",
       "mean     119.342400     58.548198  10085.463286     31.269538          -99.0   \n",
       "std       97.136655    100.504995   1349.646573    101.462163            0.0   \n",
       "min     -168.000000  -9999.000000  -9999.000000      1.000000          -99.0   \n",
       "25%       37.000000      0.000000  10122.000000     10.000000          -99.0   \n",
       "50%      116.000000     58.000000  10169.000000     26.000000          -99.0   \n",
       "75%      194.000000    124.000000  10226.000000     30.000000          -99.0   \n",
       "max      391.000000    236.000000  10474.000000    999.000000          -99.0   \n",
       "\n",
       "          precip_mm  \n",
       "count  48674.000000  \n",
       "mean     165.729178  \n",
       "std      364.906361  \n",
       "min        0.000000  \n",
       "25%        5.000000  \n",
       "50%        8.000000  \n",
       "75%        8.000000  \n",
       "max      999.000000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90905111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        location_id  sensors_id   location                   datetime  \\\n",
       "0              NaN         NaN        NaN  2020-01-01 02:00:00+02:00   \n",
       "1              NaN         NaN        NaN  2020-01-01 03:00:00+02:00   \n",
       "2              NaN         NaN        NaN  2020-01-01 04:00:00+02:00   \n",
       "3              NaN         NaN        NaN  2020-01-01 05:00:00+02:00   \n",
       "4              NaN         NaN        NaN  2020-01-01 06:00:00+02:00   \n",
       "...            ...         ...        ...                        ...   \n",
       "49213       9369.0     28602.0  IS-1-9369  2025-08-20 20:00:00+03:00   \n",
       "49214       9369.0     28602.0  IS-1-9369  2025-08-20 21:00:00+03:00   \n",
       "49215       9369.0     28602.0  IS-1-9369  2025-08-20 22:00:00+03:00   \n",
       "49216       9369.0     28602.0  IS-1-9369  2025-08-20 23:00:00+03:00   \n",
       "49217       9369.0     28602.0  IS-1-9369  2025-08-21 00:00:00+03:00   \n",
       "\n",
       "             lat        lon parameter  units      value  temp_C  dewpoint_C  \\\n",
       "0            NaN        NaN       NaN    NaN        NaN    45.0       -11.0   \n",
       "1            NaN        NaN       NaN    NaN        NaN    45.0        -5.0   \n",
       "2            NaN        NaN       NaN    NaN        NaN    47.0        -4.0   \n",
       "3            NaN        NaN       NaN    NaN        NaN    45.0        -2.0   \n",
       "4            NaN        NaN       NaN    NaN        NaN    44.0        -2.0   \n",
       "...          ...        ...       ...    ...        ...     ...         ...   \n",
       "49213  47.156836  27.574908       no2  µg/m³  33.613450     NaN         NaN   \n",
       "49214  47.156836  27.574908       no2  µg/m³  69.959590     NaN         NaN   \n",
       "49215  47.156836  27.574908       no2  µg/m³  88.330060     NaN         NaN   \n",
       "49216  47.156836  27.574908       no2  µg/m³  90.182830     NaN         NaN   \n",
       "49217  47.156836  27.574908       no2  µg/m³  42.274666     NaN         NaN   \n",
       "\n",
       "       slp_hPa  wind_dir_deg  wind_speed_ms sky_cover  precip_mm  \n",
       "0      10199.0          29.0            NaN         0        7.0  \n",
       "1      10202.0          30.0            NaN         0        7.0  \n",
       "2      10206.0          30.0            NaN         0        8.0  \n",
       "3      10209.0          31.0            NaN         0        8.0  \n",
       "4      10211.0          31.0            NaN         0        8.0  \n",
       "...        ...           ...            ...       ...        ...  \n",
       "49213      NaN           NaN            NaN       NaN        NaN  \n",
       "49214      NaN           NaN            NaN       NaN        NaN  \n",
       "49215      NaN           NaN            NaN       NaN        NaN  \n",
       "49216      NaN           NaN            NaN       NaN        NaN  \n",
       "49217      NaN           NaN            NaN       NaN        NaN  \n",
       "\n",
       "[49218 rows x 16 columns]>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a67fa5",
   "metadata": {},
   "source": [
    "| Column       | Description                                                                 | Example value              |\n",
    "|--------------|-----------------------------------------------------------------------------|----------------------------|\n",
    "| location_id  | Unique numeric identifier of the monitoring location                        | 9369                       |\n",
    "| sensors_id   | Unique numeric identifier of the sensor within the location                 | 28602                      |\n",
    "| location     | Station code (often country code + site code + location ID)                 | RO0083A-9369               |\n",
    "| datetime     | Timestamp of measurement (ISO 8601 with timezone)                          | 2020-08-04T01:00:00+03:00  |\n",
    "| lat          | Latitude coordinate of the monitoring location                             | 47.1567664986992           |\n",
    "| lon          | Longitude coordinate of the monitoring location                            | 27.5748656243897           |\n",
    "| parameter    | Pollutant measured (e.g., `no2`, `pm10`, `pm25`, `o3`, etc.)               | no2                        |\n",
    "| units        | Units of measurement (varies by parameter)                                 | µg/m³                      |\n",
    "| value        | Recorded measurement value of the pollutant                                | 51.44521273                |\n",
    "\n",
    "\n",
    "| Column (raw)       | Description                                                                 | Units (raw)       | Missing code |\n",
    "|--------------------|-----------------------------------------------------------------------------|------------------|--------------|\n",
    "| year               | Year (4-digit)                                                             | YYYY             | –            |\n",
    "| month              | Month (2-digit)                                                            | MM               | –            |\n",
    "| day                | Day of month (2-digit)                                                     | DD               | –            |\n",
    "| hour               | Hour of day (UTC, 0–23)                                                     | HH               | –            |\n",
    "| air temperature    | Air temperature in **tenths of °C**                                         | 0.1 °C           | -9999        |\n",
    "| dew point temp     | Dew point temperature in **tenths of °C**                                   | 0.1 °C           | -9999        |\n",
    "| sea level pressure | Sea level pressure in **tenths of hPa**                                     | 0.1 hPa          | -9999        |\n",
    "| wind direction     | Wind direction from true north (0–360)                                      | degrees          | -999         |\n",
    "| wind speed         | Wind speed in **tenths of m/s**                                             | 0.1 m/s          | -9999        |\n",
    "| sky cover          | Cloud cover indicator (coded, e.g., oktas or station code dependent)        | categorical/code | -9999        |\n",
    "| precipitation      | Precipitation depth during the past hour                                    | mm               | -9999        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb31b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Issues Found:\n",
      "  impossible_no2: 3930 records\n"
     ]
    }
   ],
   "source": [
    "def identify_quality_issues(df):\n",
    "    \"\"\"Comprehensive data quality assessment\"\"\"\n",
    "    issues = {}\n",
    "    \n",
    "    # Check for impossible values (domain-specific)\n",
    "    if 'temp_C' in df.columns:\n",
    "        impossible_temps = df[(df['temp_C'] < -500) | (df['temp_C'] > 700)]\n",
    "        issues['impossible_temperatures'] = len(impossible_temps)\n",
    "    \n",
    "    if 'value' in df.columns:\n",
    "        impossible_no2 = df[(df['value'] < 0 | (df['value'] > 300))]\n",
    "        issues['impossible_no2'] = len(impossible_no2)\n",
    "    \n",
    "    # Check for future dates\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "        future_dates = df[df['timestamp'] > datetime.now()]\n",
    "        issues['future_dates'] = len(future_dates)\n",
    "    \n",
    "    # Check for format inconsistencies\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        unique_patterns = df[col].astype(str).str.len().value_counts()\n",
    "        if len(unique_patterns) > 10:  # Many different lengths suggest format issues\n",
    "            issues[f'{col}_format_inconsistency'] = len(unique_patterns)\n",
    "    \n",
    "    return issues\n",
    "\n",
    "# Run quality assessment\n",
    "quality_report = identify_quality_issues(df_cleaned)\n",
    "print(\"Data Quality Issues Found:\")\n",
    "for issue, count in quality_report.items():\n",
    "    if count > 0:\n",
    "        print(f\"  {issue}: {count} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1a83dade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>sensors_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>value</th>\n",
       "      <th>temp_C</th>\n",
       "      <th>dewpoint_C</th>\n",
       "      <th>slp_hPa</th>\n",
       "      <th>wind_dir_deg</th>\n",
       "      <th>wind_speed_ms</th>\n",
       "      <th>precip_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22081.0</td>\n",
       "      <td>22081.0</td>\n",
       "      <td>22081.000000</td>\n",
       "      <td>22081.000000</td>\n",
       "      <td>22081.000000</td>\n",
       "      <td>48669.000000</td>\n",
       "      <td>48640.000000</td>\n",
       "      <td>48443.000000</td>\n",
       "      <td>47734.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9369.0</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>47.156800</td>\n",
       "      <td>27.574886</td>\n",
       "      <td>31.661637</td>\n",
       "      <td>119.364832</td>\n",
       "      <td>59.065399</td>\n",
       "      <td>10175.869269</td>\n",
       "      <td>20.747643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.938348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>30.498318</td>\n",
       "      <td>97.116429</td>\n",
       "      <td>77.021606</td>\n",
       "      <td>82.033924</td>\n",
       "      <td>10.640461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.411636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9369.0</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>47.156766</td>\n",
       "      <td>27.574866</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-168.000000</td>\n",
       "      <td>-187.000000</td>\n",
       "      <td>9881.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9369.0</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>47.156766</td>\n",
       "      <td>27.574866</td>\n",
       "      <td>15.896116</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10123.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9369.0</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>47.156766</td>\n",
       "      <td>27.574866</td>\n",
       "      <td>29.376155</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>10169.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9369.0</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>47.156836</td>\n",
       "      <td>27.574908</td>\n",
       "      <td>43.917378</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>10227.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9369.0</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>47.156836</td>\n",
       "      <td>27.574908</td>\n",
       "      <td>2217.676463</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>10474.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       location_id  sensors_id           lat           lon         value  \\\n",
       "count      22081.0     22081.0  22081.000000  22081.000000  22081.000000   \n",
       "mean        9369.0     28602.0     47.156800     27.574886     31.661637   \n",
       "std            0.0         0.0      0.000035      0.000021     30.498318   \n",
       "min         9369.0     28602.0     47.156766     27.574866     -1.000000   \n",
       "25%         9369.0     28602.0     47.156766     27.574866     15.896116   \n",
       "50%         9369.0     28602.0     47.156766     27.574866     29.376155   \n",
       "75%         9369.0     28602.0     47.156836     27.574908     43.917378   \n",
       "max         9369.0     28602.0     47.156836     27.574908   2217.676463   \n",
       "\n",
       "             temp_C    dewpoint_C       slp_hPa  wind_dir_deg  wind_speed_ms  \\\n",
       "count  48669.000000  48640.000000  48443.000000  47734.000000            0.0   \n",
       "mean     119.364832     59.065399  10175.869269     20.747643            NaN   \n",
       "std       97.116429     77.021606     82.033924     10.640461            NaN   \n",
       "min     -168.000000   -187.000000   9881.000000      1.000000            NaN   \n",
       "25%       37.000000      0.000000  10123.000000     10.000000            NaN   \n",
       "50%      116.000000     58.000000  10169.000000     26.000000            NaN   \n",
       "75%      194.000000    124.000000  10227.000000     30.000000            NaN   \n",
       "max      391.000000    236.000000  10474.000000     36.000000            NaN   \n",
       "\n",
       "          precip_mm  \n",
       "count  40842.000000  \n",
       "mean       5.938348  \n",
       "std        2.411636  \n",
       "min        0.000000  \n",
       "25%        4.000000  \n",
       "50%        7.000000  \n",
       "75%        8.000000  \n",
       "max        9.000000  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.replace([-9999, -999, -99, 9999, 999], np.nan, inplace=True)\n",
    "df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "079ada92",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_log(\n",
    "    \"outputs/logs/data_cleaning_log.txt\",\n",
    "    [\n",
    "        f\"Replaced values with missing code with nan [-9999, -999, -99, 9999, 999]\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "96e3cdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_id      float64\n",
      "sensors_id       float64\n",
      "location          object\n",
      "datetime          object\n",
      "lat              float64\n",
      "lon              float64\n",
      "parameter         object\n",
      "units             object\n",
      "value            float64\n",
      "temp_C           float64\n",
      "dewpoint_C       float64\n",
      "slp_hPa          float64\n",
      "wind_dir_deg     float64\n",
      "wind_speed_ms    float64\n",
      "sky_cover         object\n",
      "precip_mm        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f97910cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "datetime64[ns, Europe/Bucharest]\n",
      "0   2020-01-01 02:00:00+02:00\n",
      "1   2020-01-01 03:00:00+02:00\n",
      "2   2020-01-01 04:00:00+02:00\n",
      "Name: datetime, dtype: datetime64[ns, Europe/Bucharest]\n"
     ]
    }
   ],
   "source": [
    "# Confirm that date time format is consistent\n",
    "print(df_cleaned[\"datetime\"].dtype)\n",
    "\n",
    "# Coerce to datetime with timezone awareness\n",
    "df_cleaned[\"datetime\"] = pd.to_datetime(df_cleaned[\"datetime\"], errors=\"coerce\", utc=True)\n",
    "# Convert from UTC to Iași local time (Europe/Bucharest)\n",
    "df_cleaned[\"datetime\"] = df_cleaned[\"datetime\"].dt.tz_convert(\"Europe/Bucharest\")\n",
    "\n",
    "print(df_cleaned[\"datetime\"].dtype)      # should show: datetime64[ns, Europe/Bucharest]\n",
    "print(df_cleaned[\"datetime\"].head(3))    # should print like: 2025-08-20 20:00:00+03:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1769231",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_log(\n",
    "    \"outputs/logs/data_cleaning_log.txt\",\n",
    "    [\n",
    "        f\"Original datetime type: {df[\"datetime\"].dtype}\",\n",
    "        f\"Final type: {df_cleaned[\"datetime\"].dtype}\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8bc70935",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_dict = {\n",
    "    'location_id': 'int64',\n",
    "    'sensors_id': 'int64',\n",
    "    'location': 'category',\n",
    "    'lat': 'float64',\n",
    "    'lon': 'float64',\n",
    "    'parameter': 'category',\n",
    "    'units': 'category',\n",
    "    'value': 'float64',\n",
    "    'temp_C': 'float64',\n",
    "    'dewpoint_C': 'float64',\n",
    "    'slp_hPa': 'float64',\n",
    "    'wind_dir_deg': 'float64',\n",
    "    'wind_speed_ms': 'float64',\n",
    "    'sky_cover': 'category',\n",
    "    'precip_mm': 'float64'\n",
    "}\n",
    "\n",
    "for column, dtype in conversion_dict.items():\n",
    "    if column in df_cleaned.columns:\n",
    "        df_cleaned[column] = df_cleaned[column].astype(dtype, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3a824766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_id                               float64\n",
      "sensors_id                                float64\n",
      "location                                 category\n",
      "datetime         datetime64[ns, Europe/Bucharest]\n",
      "lat                                       float64\n",
      "lon                                       float64\n",
      "parameter                                category\n",
      "units                                    category\n",
      "value                                     float64\n",
      "temp_C                                    float64\n",
      "dewpoint_C                                float64\n",
      "slp_hPa                                   float64\n",
      "wind_dir_deg                              float64\n",
      "wind_speed_ms                             float64\n",
      "sky_cover                                category\n",
      "precip_mm                                 float64\n",
      "dtype: object\n",
      "       location_id  sensors_id      location                  datetime  \\\n",
      "20000       9369.0     28602.0  RO0083A-9369 2022-04-15 01:00:00+03:00   \n",
      "20001       9369.0     28602.0  RO0083A-9369 2022-04-15 02:00:00+03:00   \n",
      "20002       9369.0     28602.0  RO0083A-9369 2022-04-15 03:00:00+03:00   \n",
      "20003       9369.0     28602.0  RO0083A-9369 2022-04-15 04:00:00+03:00   \n",
      "20004       9369.0     28602.0  RO0083A-9369 2022-04-15 05:00:00+03:00   \n",
      "\n",
      "             lat        lon parameter  units      value  temp_C  dewpoint_C  \\\n",
      "20000  47.156766  27.574866       no2  µg/m³  46.407045    65.0         1.0   \n",
      "20001  47.156766  27.574866       no2  µg/m³  38.815734    57.0         0.0   \n",
      "20002  47.156766  27.574866       no2  µg/m³  33.187330    47.0        -2.0   \n",
      "20003  47.156766  27.574866       no2  µg/m³  32.256013    20.0        -1.0   \n",
      "20004  47.156766  27.574866       no2  µg/m³  39.705857    12.0       -18.0   \n",
      "\n",
      "       slp_hPa  wind_dir_deg  wind_speed_ms sky_cover  precip_mm  \n",
      "20000  10224.0          29.0            NaN         0        0.0  \n",
      "20001  10223.0          30.0            NaN         0        0.0  \n",
      "20002  10221.0          29.0            NaN         0        0.0  \n",
      "20003  10221.0           NaN            NaN       0 -        NaN  \n",
      "20004  10215.0          12.0            NaN         5        0.0  \n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned.dtypes)\n",
    "print(df_cleaned[20000:20005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eeeede10",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_log(\n",
    "    \"outputs/logs/data_cleaning_log.txt\",\n",
    "    [\n",
    "        f\"Original data typs: {df.dtypes}\"\n",
    "        f\"Final data types: {df_cleaned.dtypes}\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "af41be21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing air quality entries per year:\n",
      "year\n",
      "2020    5893\n",
      "2021    2082\n",
      "2022    6693\n",
      "2023    8684\n",
      "2024    3286\n",
      "2025     499\n",
      "dtype: int64\n",
      "Rows with present air quality entries per year:\n",
      "year\n",
      "2020    2879\n",
      "2021    6651\n",
      "2022    2024\n",
      "2024    5466\n",
      "2025    5061\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract year\n",
    "df_cleaned[\"year\"] = df_cleaned[\"datetime\"].dt.year\n",
    "\n",
    "# Count rows with missing air quality data per year\n",
    "missing_counts = (\n",
    "    df_cleaned[df_cleaned[\"location_id\"].isna()]\n",
    "    .groupby(\"year\")\n",
    "    .size()\n",
    ")\n",
    "\n",
    "present_counts = (\n",
    "    df_cleaned[df_cleaned[\"location_id\"].notna()]\n",
    "    .groupby(\"year\")\n",
    "    .size()\n",
    ")\n",
    "\n",
    "print(\"Rows with missing air quality entries per year:\")\n",
    "print(missing_counts)\n",
    "\n",
    "print(\"Rows with present air quality entries per year:\")\n",
    "print(present_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c670b78d",
   "metadata": {},
   "source": [
    "Standard random train/test splitting is not appropriate for time-series data because it assumes that all observations are independent and identically distributed. In reality, air quality and meteorological data are sequential, and each observation is influenced by temporal patterns such as seasonality, daily cycles, or longer-term trends. If the data were shuffled randomly, the model could inadvertently use information from the future to predict the past, creating data leakage and artificially inflating performance metrics.\n",
    "\n",
    "To address this, the project uses TimeSeriesSplit, which preserves chronological order when creating training and testing datasets. In this approach, the model is always trained on earlier periods and tested on later ones, reflecting the real-world task of forecasting future air quality based on past conditions. Instead of relying on a single cut between train and test sets, TimeSeriesSplit generates multiple rolling splits. This makes it possible to evaluate model performance across different time periods, providing a more robust sense of how well the model generalizes.\n",
    "\n",
    "This method is particularly valuable for air quality forecasting in Iași, where non-stationary effects such as heating in winter or traffic intensity during specific months can significantly influence pollutant concentrations. By using a time-aware validation strategy, the project ensures that the evaluation reflects these real variations. Ultimately, this leads to more realistic and trustworthy forecasts, which are crucial if the model is to support sustainable urban planning and public health decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "67b97541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n",
      "  Train: 0 to 8202\n",
      "  Test:  8203 to 16405\n",
      "Fold 3:\n",
      "  Train: 0 to 16405\n",
      "  Test:  16406 to 24608\n",
      "Fold 4:\n",
      "  Train: 0 to 24608\n",
      "  Test:  24609 to 32811\n",
      "Fold 5:\n",
      "  Train: 0 to 32811\n",
      "  Test:  32812 to 41014\n",
      "Fold 6:\n",
      "  Train: 0 to 41014\n",
      "  Test:  41015 to 49217\n"
     ]
    }
   ],
   "source": [
    "# Create time series splits for cross-validation*\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "folds = {}\n",
    "for i, (train_idx, test_idx) in enumerate(tscv.split(df_cleaned), start=1):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    print(f\"  Train: {train_idx[0]} to {train_idx[-1]}\")\n",
    "    print(f\"  Test:  {test_idx[0]} to {test_idx[-1]}\")\n",
    "    folds[f\"fold_{i}\"] = {\n",
    "        \"X_Train\": df_cleaned.iloc[train_idx],\n",
    "        \"X_Test\": df_cleaned.iloc[test_idx],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "858ffe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_log(\n",
    "    \"outputs/logs/data_cleaning_log.txt\",\n",
    "    [\n",
    "        f\"Temporal split using TimeSeriesSplit with n_splits=5\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25bf56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
